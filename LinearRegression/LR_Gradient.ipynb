{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJz8ZxU7opMy"
   },
   "source": [
    "\n",
    "\n",
    "# Implementation of linear regression using gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dW1xPyXPoonO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class linear_regression:\n",
    "    def __init__(self, learning_rate, iterations, \n",
    "               fit_intercept=True, normalize=False, coef=None):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.coef = coef\n",
    "        self.cost =0\n",
    "  \n",
    "    #Normalizing the X values by subracting it with the mean and dividing it with standard deviation.\n",
    "    def normalize_Data(self,X):\n",
    "        no_of_features=X.shape[1]\n",
    "        X_normalized=X\n",
    "    \n",
    "        Mean=np.zeros(no_of_features)\n",
    "        Standard_deviation=np.zeros(no_of_features)\n",
    "        \n",
    "        X_normalized= X-np.mean(X,axis=0)/np.std(X,axis=0)\n",
    "        return X_normalized \n",
    "\n",
    " \n",
    "    def fit(self, X, y):\n",
    "       \n",
    "    #If we put normalize as true then only it will normalize the X values \n",
    "        if self.normalize:\n",
    "            X=self.normalize_Data(X)\n",
    "            \n",
    "    #Taking into account the number of columns and rows of the data and also the lenght of them.\n",
    "        No_of_columns=X.shape[1]\n",
    "        no_of_rows=X.shape[0]\n",
    "        length_of_X= len(X)\n",
    "        length_of_y= len(y)\n",
    "       \n",
    "    #If we put intercept to true then add one's column wise; c_ adds values column wise \n",
    "    #if we put intercept is false then the X remains the same\n",
    "        if self.fit_intercept:\n",
    "            Weights_dimension=No_of_columns + 1\n",
    "            Modified_X= np.c_[np.ones((length_of_X,1)),X]\n",
    "        else:\n",
    "            Weights_dimension=No_of_columns\n",
    "            Modified_X = X\n",
    "            \n",
    "        #M is the weight vector. We are initializing the weight vector by taking zeros. We can also take random values to intialize it.\n",
    "        self.M=np.zeros(Weights_dimension)\n",
    "        X_T=np.transpose(Modified_X)\n",
    "        self.cost=0\n",
    "       \n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            #y_hat is the y we predicted which can be obtained by multipying our X and M which is our weight vector\n",
    "            y_hat=np.dot(Modified_X,self.M)\n",
    "            error_vector= np.dot(X_T,y_hat-y)\n",
    "            #implementing the actual formulae weight=weight-(1/number of rows)*learning rate*(summ of ypredicted-actualy)*X\n",
    "            #the error is the summation of ypred-y actual \n",
    "            self.M=self.M-(1/no_of_rows)*self.learning_rate*(error_vector)\n",
    "            self.cost= np.sum((y_hat-y)**2)/2*no_of_rows\n",
    "        return self.M,self.cost\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        length_of_X= len(X)\n",
    "    \n",
    "        if self.fit_intercept:\n",
    "            Modified_X= np.c_[np.ones((length_of_X,1)),X]\n",
    "        else:\n",
    "            Modified_X = X\n",
    "            \n",
    "            #The predicted value \n",
    "            prediction=np.dot(X,self.M)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Man3c1JrhVbr"
   },
   "source": [
    "## Problem 1.2 (10 points)\n",
    "\n",
    "- Split the Boston Housing dataset into train and test sets (70% and 30%, respectively) (5 points). \n",
    "- Fit your linear regression implementation using the training set and print your model's coefficients. Make predictions for the test set using your fitted model (5 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEFBL6WwhXUz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.05022161, 20.52910395, 21.64194652, 24.02955968, 21.74400224,\n",
       "        6.55804271, 27.64541769, 21.40999715, 22.20333231, 20.92341822,\n",
       "       22.78100979, 31.07811375, 23.53969798, 24.33393075, 20.79586313,\n",
       "       21.5151255 , 20.22217616,  6.74661551, 23.42710707, 18.30922938,\n",
       "       32.16900166, 23.54177321, 22.33651012, 18.7086258 , 21.5246299 ,\n",
       "       21.77785827, 21.91653255, 22.74537039, 23.0071897 , 22.54171012,\n",
       "       20.23008668, 21.53231062, 22.65394127, 21.23086582, 23.92653525,\n",
       "       23.68685044, 21.44488765, 21.00939822, 22.49707866, 23.9833305 ,\n",
       "       19.80955846, 23.23436628, 23.04043995, 21.67085787, 16.59595134,\n",
       "       22.02292817, 21.91530143, 22.25810157, 20.91945964, 23.41097142,\n",
       "       22.42321506, 22.28111958, 17.37279039, 22.65224749, 26.2221944 ,\n",
       "       22.35096623, 24.59564973, 29.12692301, 22.23082348, 22.85632858,\n",
       "       22.81963338, 28.09093858, 20.33912184, 21.73392885, 21.32218863,\n",
       "       20.37833627, 22.96939231, 21.80390328, 22.90076625, 19.98205489,\n",
       "       24.32859461, 32.93501568, 21.44633107, 25.06578929, 23.40735111,\n",
       "       21.04081823, 25.41266274, 24.75679384, 24.87875843, 22.50384639,\n",
       "       22.5922146 , 23.84327067, 22.25518405, 23.28109463, 24.15131417,\n",
       "       22.1856263 , 21.42241906, 21.62893799, 22.55862451, 23.46405785,\n",
       "        8.56867858, 28.61155161, 25.37539995, 32.52748607, 20.71858835,\n",
       "       21.87599746, 22.32688155, 28.96870199, 28.47691431, 23.14034397,\n",
       "       22.69919227, 33.58816496, 24.10722882, 22.88321656, 24.87396515,\n",
       "       22.23726193, 20.22838377, 24.09533792, 22.60182273, 31.85852659,\n",
       "       21.51596963, 20.97612627, 24.19041001,  5.8829942 , 22.56980762,\n",
       "       24.00227093, 22.29643755, 22.47729961, 21.06562251, 18.63803101,\n",
       "       19.69199033, 21.7029517 , 31.93703859, 24.51776124, 24.90428517,\n",
       "       20.95484523,  2.8606782 , 23.26997388,  4.92153222, 22.6675151 ,\n",
       "       19.94150005,  1.13020492, 19.04573509, 21.9345138 , 21.11782673,\n",
       "       21.65260144, 26.74534735, 22.18616945, 22.82073554,  2.49719509,\n",
       "       22.37968056, 21.90424662, 31.36918681, 21.85576578, 21.72179145,\n",
       "       31.39445969, 22.22565913, 23.49279076, 22.70259458, 23.02056128,\n",
       "       23.30073871, 21.3434654 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading the boston data set \n",
    "dataset = load_boston()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "#Splitting the data set into 70percent train and 30percent test \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "#Calling the linear regression class which i have designed above\n",
    "regresser=linear_regression(learning_rate=0.000001,iterations=5000,fit_intercept=False, normalize=True, coef=None)\n",
    "\n",
    "#fitting the model \n",
    "regresser.fit(X_train,y_train)\n",
    "\n",
    "#predicted values \n",
    "y_pred=regresser.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcqYa1U3iRQ1"
   },
   "source": [
    "## Questions\n",
    "\n",
    "1. How do you interpret that a variable causes a model's mean square error to increase? \n",
    "  - Answer:\n",
    "  So basically we plot the best fit line for our linear regression model and check the number of data points which are close to the best fit line.Generally the term used to check the closeness is Rsquare. As we check the number of points close to the best fit line there may be some data points which are very far away from the line these are nothing but outliers. The outliers are the points which cause our models mean square error to increase. \n",
    "  \n",
    "  \n",
    "2. Why we would want to normalize our variables? \n",
    "  - Answer: \n",
    "  In some cases few points in our data will have very high values which will dominate the other data points which will lead to a confused bad model. Instead if we normalize the data we wont be facing this domination issue. Usually we apply log function for normalization\n",
    "  \n",
    "  \n",
    "  \n",
    "3. A model fitted using the exact same split dataset with normalized values will generate the same coefficients as a model that was fitted using values that haven't been normalized. Clearly state whether that statement is true or false and explain your reasoning. \n",
    "  - Answer:\n",
    "   False\n",
    "   reason:- if we dont normalize there may be some points which may show domination which may influence the model.So by normalizing we wont have many dominant points.So as we are normalizing the coeffcients will be differnt.On the other side if the data is already normalized then coefficients wont change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "A1-F19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
